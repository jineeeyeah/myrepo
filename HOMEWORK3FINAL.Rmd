---
title: "hw333"
output: html_document
date: '2022-04-19'
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Classification

For this assignment, we will be working with part of a [Kaggle data set](https://www.kaggle.com/c/titanic/overview) that was the subject of a machine learning competition and is often used for practicing ML models. The goal is classification; specifically, to predict which passengers would survive the [Titanic shipwreck](https://en.wikipedia.org/wiki/Titanic).


Load the data from `data/titanic.csv` into *R* and familiarize yourself with the variables it contains using the codebook (`data/titanic_codebook.txt`).
```{r}
setwd("C:/Users/82107/Documents/myrepo/hw3333/HOMEWORK3")

data <-read.csv(file="titanic.csv",stringsAsFactors = FALSE,header = TRUE)
```


Notice that `survived` and `pclass` should be changed to factors. When changing `survived` to a factor, you may want to reorder the factor so that *"Yes"* is the first level.

```{r}
data$survived <- as.factor(data$survived)
data$pclass <- as.factor(data$pclass)
data$survived <- factor(data$survived, levels = c('Yes', 'No'))
```


Make sure you load the `tidyverse` and `tidymodels`!
```{r}
library(tidyverse)
library(tidymodels)
```

*Remember that you'll need to set a seed at the beginning of the document to reproduce your results.*

```{r}
set.seed(1234)
```

### Question 1

Split the data, stratifying on the outcome variable, `survived.`  You should choose the proportions to split the data into. Verify that the training and testing data sets have the appropriate number of observations. Take a look at the training data and note any potential issues, such as missing data.

```{r}
titanic_split <- initial_split(data, prop = 0.8, strata = survived)
titanic_train <- training(titanic_split)
titanic_test <- testing(titanic_split)

```

```{r}
# Verify that the training and testing data sets have the appropriate number of observations
nrow(titanic_train) # 712
nrow(titanic_test) # 179
```

```{r}
# Take a look at the training data and note any potential issues, such as missing data.
x <- length(names(titanic_train))
y <- cbind(names(titanic_train),1:x)
for(i in 1:x){
  y[i,2] <- sum(is.na(titanic_train[,i]))
}
y
table(is.na(titanic_train$age))
table(is.na(titanic_train$cabin))
table(is.na(titanic_train$embarked))
```


Why is it a good idea to use stratified sampling for this data?

```{r}
# It is a good idea to use stratified sampling for this data, because the proportion of missing values is still same.
```


### Question 2

Using the **training** data set, explore/describe the distribution of the outcome variable `survived`.

```{r}
titanic_train %>% 
  ggplot(aes(x = survived)) +
  geom_bar()

```


### Question 3

Using the **training** data set, create a correlation matrix of all continuous variables. Create a visualization of the matrix, and describe any patterns you see. Are any predictors correlated with each other? Which ones, and in which direction?

```{r}

library(corrr)
cor_train <- titanic_train %>%
  select(is.numeric) %>%
  correlate()
rplot(cor_train)

cor_train %>%
  stretch() %>%
  ggplot(aes(x, y, fill = r)) +
  geom_tile() +
  geom_text(aes(label = as.character(fashion(r))))

```
```{r}
# Describe any patterns you see. Are any predictors correlated with each other? Which ones, and in which direction?
# 'parch' and 'sib_sp' are correlated with each other, in positive direction.
# 'age' and 'sib_sp' are correlated with each other, in negative direction.
```

### Question 4

Using the **training** data, create a recipe predicting the outcome variable `survived`. Include the following predictors: ticket class, sex, age, number of siblings or spouses aboard, number of parents or children aboard, and passenger fare.

```{r}
titanic_recipe <- recipe(survived ~ pclass + sex + age + sib_sp + 
                           parch + fare, data = titanic_train) %>%
  step_impute_linear(age) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_interact(terms = ~starts_with("sex"):fare+age:fare)

titanic_recipe
```

Recall that there were missing values for `age`. To deal with this, add an imputation step using `step_impute_linear()`. Next, use `step_dummy()` to **dummy** encode categorical predictors. Finally, include interactions between:

-   Sex and passenger fare, and
-   Age and passenger fare.
 

You'll need to investigate the `tidymodels` documentation to find the appropriate step functions to use.

### Question 5

Specify a **logistic regression** model for classification using the `"glm"` engine. Then create a workflow. Add your model and the appropriate recipe. Finally, use `fit()` to apply your workflow to the **training** data.

***Hint: Make sure to store the results of `fit()`. You'll need them later on.***

```{r}
log_reg <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")


lr_wkflow <- workflow() %>%
  add_model(log_reg) %>%
  add_recipe(titanic_recipe)

lr_fit<- fit(lr_wkflow,titanic_train)

lr_fit %>%
  tidy()
```


### Question 6

**Repeat Question 5**, but this time specify a linear discriminant analysis model for classification using the `"MASS"` engine.
```{r}
library(discrim)
lda_mod <- discrim_linear() %>%
  set_engine("MASS") %>%
  set_mode("classification") 

lda_wkflow <- workflow() %>%
  add_model(lda_mod) %>%
  add_recipe(titanic_recipe)

lda_fit<- fit(lda_wkflow,titanic_train)

```


### Question 7

**Repeat Question 5**, but this time specify a quadratic discriminant analysis model for classification using the `"MASS"` engine.

```{r}
qda_mod <- discrim_quad() %>%
  set_engine("MASS") %>%
  set_mode("classification")


qda_wkflow <- workflow() %>%
  add_model(qda_mod) %>%
  add_recipe(titanic_recipe)

qda_fit<- fit(qda_wkflow,titanic_train)
```


### Question 8

**Repeat Question 5**, but this time specify a naive Bayes model for classification using the `"klaR"` engine. Set the `usekernel` argument to `FALSE`.

```{r}
library(klaR)
library(ISLR)
library(ISLR2)
library(poissonreg)
tidymodels_prefer()

nb_mod <- naive_Bayes() %>%
  set_mode("classification") %>%
  set_engine("klaR") %>%
  set_args(usekernel = FALSE)


nb_wkflow <- workflow() %>%
  add_model(nb_mod) %>%
  add_recipe(titanic_recipe)

nb_fit<- fit(nb_wkflow,titanic_train)

```

### Question 9

Now you've fit four different models to your training data.

Use `predict()` and `bind_cols()` to generate predictions using each of these 4 models and your **training** data. Then use the *accuracy* metric to assess the performance of each of the four models.

Which model achieved the highest accuracy on the training data?

```{r}
p1 <- predict(lr_fit, new_data = titanic_train, type = "prob")
p2 <- predict(lda_fit, new_data = titanic_train, type = "prob")
p3 <- predict(qda_fit, new_data = titanic_train, type = "prob")
p4 <- predict(nb_fit, new_data = titanic_train, type = "prob")


pred1 <- bind_cols(p1, titanic_train)

pred2 <- bind_cols(p2, titanic_train)

pred3 <- bind_cols(p3, titanic_train)

pred4 <- bind_cols(p4, titanic_train)


lr_ac <- augment(lr_fit, new_data = titanic_train) %>%
  accuracy(truth = survived, estimate = .pred_class)
lr_ac

lda_ac <- augment(lda_fit, new_data = titanic_train) %>%
  accuracy(truth = survived, estimate = .pred_class)
lda_ac

qda_ac <- augment(qda_fit, new_data = titanic_train) %>%
  accuracy(truth = survived, estimate = .pred_class)
qda_ac

nb_ac <- augment(nb_fit, new_data = titanic_train) %>%
  accuracy(truth = survived, estimate = .pred_class)
nb_ac


accuracies <- c(lr_ac$.estimate, lda_ac$.estimate, 
                qda_ac$.estimate, nb_ac$.estimate)
models <- c("Logistic Regression", "LDA", "QDA", "Naive Bayes")
results <- tibble(accuracies = accuracies, models = models)
results %>% 
  arrange(-accuracies)
                  
```
```{r}
# Which model achieved the highest accuracy on the training data?
# Logistic Regression model achieved the highest accuracy on the training data.
```


### Question 10

Fit the model with the highest training accuracy to the **testing** data. Report the accuracy of the model on the **testing** data.

Again using the **testing** data, create a confusion matrix and visualize it. Plot an ROC curve and calculate the area under it (AUC).

```{r}
# Fit the model with the highest training accuracy
predict(lr_fit, new_data = titanic_test, type = "prob")

# Report the accuracy of the model on the testing data
multi_metric <- metric_set(accuracy, sensitivity, specificity)

# Create a confusion matrix and visualize it
augment(lr_fit, new_data = titanic_test) %>%
  conf_mat(truth = survived, estimate = .pred_class) %>%
  autoplot(type = "heatmap")


# Plot an ROC curve and calculate the area under it
augment(lr_fit, new_data = titanic_test) %>%
  roc_curve(survived, .pred_Yes) %>%
  autoplot() 

augment(lr_fit, new_data = titanic_test) %>%
  roc_auc(truth = survived, estimate = .pred_Yes)

```

How did the model perform? Compare its training and testing accuracies. If the values differ, why do you think this is so?

```{r}
# The model performs good.
compare_train <- augment(lr_fit, new_data = titanic_train) %>%
  accuracy(truth = survived, estimate = .pred_class)
compare_train

compare_test <- augment(lr_fit, new_data = titanic_test) %>%
  accuracy(truth = survived, estimate = .pred_class)
compare_test

# The training accuracy and the testing accuracy are differ. The testing accuracy is better than the training accuracy.

```

### Required for 231 Students

In a binary classification problem, let $p$ represent the probability of class label $1$, which implies that $1 - p$ represents the probability of class label $0$. The *logistic function* (also called the "inverse logit") is the cumulative distribution function of the logistic distribution, which maps a real number *z* to the open interval $(0, 1)$.

### Question 11

Given that:

$$
p(z)=\frac{e^z}{1+e^z}
$$

Prove that the inverse of a logistic function is indeed the *logit* function:

$$
z(p)=ln\left(\frac{p}{1-p}\right)
$$


$$
p(z) = 1 - 1/(1+exp(y))
$$

$$
1-p(z) = 1/(1+exp(y))
$$
$$
1+exp(y) = 1/(1-x) = (1-x)/(1-x) + x/(1-x)
$$
$$
exp(y) = x/(1-x)
$$
$$
y = logit(x) = ln(p/(1-p))
$$


### Question 12

Assume that $z = \beta_0 + \beta_{1}x_{1}$ and $p = logistic(z)$. How do the odds of the outcome change if you increase $x_{1}$ by two? Demonstrate this.

Assume now that $\beta_1$ is negative. What value does $p$ approach as $x_{1}$ approaches $\infty$? What value does $p$ approach as $x_{1}$ approaches $-\infty$?


$$
\frac{odds(x_1 +2)} {odds(x_1)} = \frac{e ^{\beta_0 + \beta_1 (x_1 +2)}} {e ^{\beta_0 + \beta_1 x_1}} 
$$

$$
= {e ^{\beta_1 (2)}}
$$

```{r}
# When $\beta_1$ is negative, $p$ approaches 0 as $x_{1}$ approaches $\infty$. 
# When $\beta_1$ is negative, $p$ approaches 1 as $x_{1}$ approaches $-\infty$.
```

