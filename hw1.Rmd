---
title: "homework1"
output: html_document
date: '2022-04-01'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Question 1.

Supervised learning is learning with supervisor(the actual data Y), and unsupervised learning is leaning without supervisor. In unsupervised learning, we can't see the answer key. The examples of supervised learning is linear regression, logistic regression, and random forests. The examples of unsupervised learning is principal component analysis(PCA), k-means clustering, and hierarchical clustering.

### Question 2.
Classification is the task of predicting a discrete class label, that Y is quantitative values(numerical values). Regression is the task of predicting a continuous quantity, that Y is qualitative values(categorical values).


### Question 3.
Two commonly used metrics for regression ML problems are MSE(Mean Squared Error), and MAE(Mean Absolute Error). Two commonly used metrics for classification ML problems are Error Rate, 


### Question 4.
Descriptive models are choosing model to best visually emphasize a trend in data. Predictive models are choosing model to predict Y with minimum reducible error, not focused on hypothesis tests. Inferential models' aim is to test theories, state relationship between outcome and predictors. 

### Question 5.
Mechanistic model is a model which assumes a parametric form for f, and won't match true unknown f. It can add parameters, which increases the flexibility. Empirically-driven model is a model which has no assumptions about f, and it requires a larger number of observations. They are similar because both model can have an overfitting problem. 

I think a mechanistic model is easier to understand in general, because parameters usually help us to understand the model easier.

The bias-variance tradeoff is the property of a model that the variance of the parameter can be reduced by increasing the bias in the parameters, and the high variance may result from overfitting problem. So, the bias-variance trade off is related to the use of mechanistic models and the empirically-driven models because both models can have an overfitting problem.


### Question 6.
I think the first question is predictive. Because the first question wants to predict how likely it is that they will vote in favor of the candidate in given situation. I think the secound question is inferential. Because the second question wants to state the relationship between outcome(How would a voter's likelihood of support for the candidate change) and predictors(the personal contact with the candidate).





### Exercise 1.

```{r}
install.packages("ggplot2", repos = "http://cran.us.r-project.org")
```
```{r}
library('ggplot2')
```

```{r}
ggplot(mpg, aes(x=hwy)) + geom_histogram()
```
Hwy become x values, and the counts of Hwy become y values naturally. According to the histogram of Hwy, we can see that there are some outliers, and the mode seems like to be about 26.

```{r}
mpg$hwy
mean(mpg$hwy)

```


### Exercise 2.


```{r}
ggplot(mpg, aes(x= hwy, y = cty)) + geom_point() + geom_line(linetype = "dashed")
```

There is a linear relation between hwy and cty. The hwy values increase in conjunction with cty values. The linear relation means that for the vehicles in this data, if the mpg value is high within city, then the mpg value is also high on the highway, relatively. And if the mpg value is also high on the highway, then the mpg value is also high within city, relatively.

### Exercise 3.
```{r}
library(ggplot2)
install.packages("forcats", repos = "http://cran.us.r-project.org")
library(forcats)
ggplot(mpg, aes(x = fct_infreq(manufacturer))) + geom_bar() + coord_flip() + labs(x = "count")
       
```
Dodge produced the most cars, and Lincoln produced the least cars.

### Exercise 4.
```{r}

cyl2 <- as.character(mpg$cyl)
ggplot(mpg, aes(x = cyl2, y = hwy)) + geom_boxplot()

ggplot(mpg, aes(group = cyl, y = hwy)) + geom_boxplot()

```
If the value of cyl is low, hwy value is increased, and if the value of cyl is high, hwy value is decreased.
There is some outliers in the lowest and the highest value of cyl.



### Exercise 5. 

```{r}
install.packages("corrplot", repos = "http://cran.us.r-project.org")

library(corrplot)
library(tidyverse)

M = cor(mpg %>% dplyr::select(where(is.numeric)))
corrplot(M,method ="number", type="lower")

mpg

```


 'displ' variable is positively correlated with 'cyl', 'cty' variable is positively correlated with 'hwy'. These relationships make sense to me, because as the number of cylinders increases the enigne displacement usually increases, and vice versa. Also, as the city miles per gallon increases the highway miles per gallon usually increases, and vice versa.  
 'cty' variable is negatively correlated with 'displ' and 'cyl'. 'hwy' variable is negatively correlated with 'displ' and 'cyl'. These relationships also make sense to me, because as the engine displacement and the number of cylinders increases, the city, highway miles per gallon usually decreases, and vice versa.


### Exercise 6
```{r}
install.packages('ggthemes', repos = "http://cran.us.r-project.org")
library(ggthemes)

library(ggplot2)

ggplot(mpg, aes(x = hwy, y = class)) + 
        geom_boxplot() +
        labs(x = 'Highway MPG', y = 'Vehicle Class') +
        theme_economist_white(gray_bg = FALSE) +
        geom_jitter(color = "grey", size = 0.7, alpha = 1) + theme(panel.grid.major.x = element_line(colour = 'grey'))

ggplot(mpg, aes(x = hwy, y = class)) + geom_jitter(color = 'grey', size = 0.7, alpha = 1) + geom_boxplot() + labs(x = 'Highway MPG', y = 'Veichle Class') + theme(panel.grid.major = element_line(colour = 'grey')) + theme(panel.background = element_rect(fill = "white", colour = "grey50")) + theme(panel.border = element_rect(colour = 'white', fill = NA)) + theme(axis.ticks = element_blank()) + theme(axis.line.x = element_line(size = 1, colour = "black"))

```

### Exercise 7

```{r}

ggplot(mpg, aes(x = class, y = hwy, fill = drv)) + geom_boxplot()

```



### Exercise 8
```{r}
ggplot(mpg, aes(x = displ, y = hwy, color = drv)) + geom_point() + geom_smooth(aes(linetype = drv), color = 'blue', se = FALSE)
```

